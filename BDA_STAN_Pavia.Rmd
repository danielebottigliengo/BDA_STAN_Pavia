--- 
title: "An Introduction to Bayesian Data Analysis with Stan"
author: "Daniele Bottigliengo"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
description: "Notes and exercises from the course on Bayesian Data Analysis with Stan taken during the 1st International Summer School at the Department of Brain and Behavioral Sciences Medical Statistics and Genomic Unit, University of Pavia, Italy."
---

# Information on the course {-}

Placeholder


## Settings {-}

<!--chapter:end:index.Rmd-->


# Foundations of Bayesian inference in theory and practice and Stan software {#day1}

Placeholder


## What is Stan?
## Bayesian workflow
## World concentration ofo PM2.5: case study
### Exploratory Data Analysis: building a network of model
### Prior Predictive Checks: fake data can be as valuable as real data
## Pest control of roaches in apartment buildings: a case study
### The goal
### Exploratory data analysis
### The model
#### Data block
#### Parameters block
#### Model block

<!--chapter:end:10-foundations.Rmd-->


# Bayesian applied regression models {#day2}

Placeholder


## Posterior predictive checks
### Negative Binomial model
## MCMC algorithms

<!--chapter:end:20-regression_models.Rmd-->


# Hierarchical/Multilevel modeling (part 1) {#day3}

Placeholder


## Pest control example: negative-binomial model
## Pest control example: hierarchical model (varying intercept)
### Preparing hierarchical data for Stan program
### Centered parametrization
### Non-centered parametrization

<!--chapter:end:30-hierarchical_models_1.Rmd-->

# Hierarchical/Multilevel modeling (part 2) {#day4}

## Varying intercept and varying slopes
We retrieved more data and thus we have more number of time points 
for each buildings we are considering. We can then add complexity to
our model allowing for varying slopes (different effect of the number
of traps for each building). The model with varying intercepts can
be formalize as follows:

$$
\text{complaints}_{b,t} \sim \text{Neg-Binomial}(\lambda_{b,t}, \phi)  \\
\lambda_{b,t} = \exp{(\eta_{b,t})}\\
\eta_{b,t} = \mu_b + \kappa_b \, \texttt{traps}_{b,t} + \text{log_sq_foot}_b \\
\mu_b \sim \text{Normal}(\alpha + \texttt{building_data} \, \zeta, \sigma_{\mu}) \\
\kappa_b \sim \text{Normal}(\beta + \texttt{building_data} \, \gamma, \sigma_{\kappa})
$$

Now let's load the new dataset.

```{r}
pest_data_longer <- readRDS(
  here::here(
    "data/pest_data_longer_stan_dat.RDS"
  )
)
```

We will fit the non-centered parametrization version of the model with
varying intercepts and slopes with. Here the code of the Stan program

```
// Hierarchical NB model with varying intercepts and slopes

functions {
  /*
  * Alternative to neg_binomial_2_log_rng() that
  * avoids potential numerical problems during warmup
  */
  int neg_binomial_2_log_safe_rng(real eta, real phi) {
    real gamma_rate = gamma_rng(phi, phi / exp(eta));
    if (gamma_rate >= exp(20.79))
      return -9;

    return poisson_rng(gamma_rate);
  }
}

data {

  int<lower=1> N;                     // number of observations
  int<lower=0> complaints[N];         // number of complaints
  vector<lower=0>[N] traps;           // number of traps
  vector[N] log_sq_foot;              // vector of exposure (offset)

  // building-level data
  int<lower=1> K;                       // number of building-level covs
  int<lower=1> J;                       // number of building
  int<lower=1, upper=J> building_idx[N];// id of the building
  matrix[J,K] building_data;            // building-level matrix

}

parameters {

  real<lower=0> inv_phi;     // inverse of the parameter phi

  // Non centered parameters for varying intercepts
  vector[J] mu_raw;        // auxiliary parameter
  real<lower=0> sigma_mu;  // sd of buildings-specific intercepts
  real alpha;              // 'global' intercept for buildings
  vector[K] zeta;          // coefficients on building-level predictors

  // Non centered parameters for varying slopes
  vector[J] kappa_raw;       // auxiliary parameter
  real<lower=0> sigma_kappa; // sd of buildings-specific slopes
  real beta;                 // 'global' slope on traps variable
  vector[K] gamma;           // coefficients on building-level predictors

}

transformed parameters {

  real phi = inv(inv_phi);  // original parameter phi

  // Original parameters mu and kappa
  vector[J] mu = alpha +
                 building_data * zeta +
                 sigma_mu * mu_raw;

  vector[J] kappa = beta +
                    building_data * gamma +
                    sigma_kappa * kappa_raw;

}

model {

  // Declare linear predictor Linear predictor
  vector[N] eta = mu[building_idx] +
                  kappa[building_idx] .* traps +
                  log_sq_foot;

  // Prior on inv_phi
  target += normal_lpdf(inv_phi | 0, 1) +

  // Prior on varying slopes parameters
            normal_lpdf(kappa_raw | 0, 1) +
            normal_lpdf(sigma_kappa | 0, 1) +
            normal_lpdf(beta | -0.25, 1) +
            normal_lpdf(gamma | 0, 1) +

  // Prior on varying intercepts parameters
            normal_lpdf(mu_raw | 0, 1) +
            normal_lpdf(sigma_mu | 0, 1) +
            normal_lpdf(alpha | log(4), 1) +
            normal_lpdf(zeta | 0, 1);

  // Likelihood
  target += neg_binomial_2_log_lpmf(complaints | eta, phi);

  // The symbol ".*" is element-wise multiplication to multiply
  // the slope of each building for the number of traps of that building

}

generated quantities {

  // Declare replicated data
  int y_rep[N];

  for (n in 1:N) {
    real eta_n = mu[building_idx[n]] +
                 kappa[building_idx[n]] * traps[n] +
                 log_sq_foot[n];

    y_rep[n] = neg_binomial_2_log_safe_rng(eta_n, phi);
  }

}
```

Fit the model to data and extract the posterior draws needed for
our posterior predictive checks.

```{r run-NB-hier-slopes}
# Compile the model
comp_model_NB_hier_slopes <- stan_model(
  'stan_programs/hier_multiple_neg_bin_ncp_var_slopes.stan'
)

# Sampling from the posterior
fitted_model_NB_hier_slopes <- sampling(
    comp_model_NB_hier_slopes,
    data = pest_data_longer,
    warmup = 1000L,
    iter = 2000L,
    chains = 4, 
    control = list(
      adapt_delta = 0.99,  # Increase the step of the chains
      max_treedepth = 15
    ),
    seed = mcmc_seed
  )
  
```

To see if the model infers building-to-building differences in, we can
plot a histogram of our marginal posterior distribution for 
`sigma_kappa`.

```{r}
mcmc_hist(
  as.matrix(
    fitted_model_NB_hier_slopes, 
    pars = "sigma_kappa"
  ),
  binwidth = 0.005
)
```

```{r}
print(
  fitted_model_NB_hier_slopes, 
  pars = c('kappa','beta','alpha','phi','sigma_mu','sigma_kappa','mu')
)
```

```{r}
mcmc_hist(
  as.matrix(
    fitted_model_NB_hier_slopes, 
    pars = "beta"
  ),
  binwidth = 0.005
)
```

While the model can't specifically rule out zero from the posterior, 
it does have mass at small non-zero numbers, so we should leave in the
hierarchy over $\texttt{kappa}$. Plotting the marginal
data density again, we can see the model still looks well calibrated.

```{r ppc-full-hier-slopes}
y_rep <- as.matrix(
  fitted_model_NB_hier_slopes, 
  pars = "y_rep"
)

ppc_dens_overlay(
  y = pest_data_longer$complaints,
  yrep = y_rep[1:200,]
)
```

## Time varying effects and structured priors

We haven't still inspect the trend of complaints over the time. We can
check if there is any pattern by comparing the observed and posterior
predictive average number of complaints over different months of the
year.

```{r ppc-group_max-hier-slopes-mean-by-mo}
select_vec <- which(pest_data_longer$mo_idx %in% 1:12)

ppc_stat_grouped(
  y = pest_data_longer$complaints[select_vec],
  yrep = y_rep[,select_vec],
  group = pest_data_longer$mo_idx[select_vec],
  stat = 'mean'
) + 
  xlim(0, 11)
```

Looking at the plot above, it seems that the average number of complaints
increases over the time. Our model was not able to capture this feature
of the data and it tend to overestimate the average number of 
complaints for many months of the year.

We can increase complexity in our model by adding a log-additive 
monthly effect to capture trend over time with an Autoregressive
(AR) model. We add into our model the term $\texttt{mo}_t$,

$$
\eta_{b,t} = \mu_b + \kappa_b \, \texttt{traps}_{b,t} + \texttt{mo}_t + \text{log_sq_foot}_b
$$

The change in the number of complaints over the time can be influenced
by several factors. It is possible that more roaches are present during
the summer as well as there is more roach control in the same season.
It is plausible to think that maybe residents are more vigilant after
the first sighting of roaches in the building, leading to an increase
in the number of complaints.

This can be a motivation for using an autoregressive prior for our 
monthly effects. With such model we are evaluating the possibility
that the number of complaints in a month is related to the number of
complaints in the previous month. The model s as follows:

$$
\texttt{mo}_t \sim \text{Normal}(\rho \, \texttt{mo}_{t-1}, \sigma_\texttt{mo}) \\
\equiv \\
\texttt{mo}_t = \rho \, \texttt{mo}_{t-1} +\epsilon_t , \quad \epsilon_t \sim \text{Normal}(0, \sigma_\texttt{mo}) \\
\quad \rho \in [-1,1]
$$

This equation says that the monthly effect in month $t$ is directly
related to the last month's monthly effect. Given the description of 
the process above, it seems like there could be either positive or
negative associations between the months, but there should be a bit more
weight placed on positive $\rho$s, so we'll put an informative prior 
that pushes the parameter $\rho$ towards 0.5.

Because Stan doesn't implement any densities that have support on 
$[-1,1]$, we must use a variable transformation of a raw variable
defined on $[0,1]$ before having the density on $\rho$ in $[-1,1]$,
that is:

$$
\rho_{\text{raw}} \in [0, 1] \\
\rho = 2 \times \rho_{\text{raw}} - 1
$$

In such a way, we can put a prior on $\rho_{raw}$ that pushes the
estimate of $\rho$ toward $0.5$.

Since we are working in a situation where the distribution of $mo_{t}$
is conditional on $mo_{t-1}$, the prior on $mo_{t}$ should follow the
same logic. But what kind of prior should we use for the first month,
i.e. $mo_{1}$?

For this first observation we need to find its marginal distribution.
We can exploit the stationary nature of AR model, that says that for
all $t$:

$$
E \left( mo_{t} \right) = E \left( mo_{t -1 } \right) \\
Var \left( mo_{t} \right) = Var \left( mo_{t -1 } \right)
$$

Hence, the marginal distribution of $mo_{t}$ will be equal to the
marginal distribution of $m_{t - 1}$.

First we derive the marginal variance of $\texttt{mo}_{t}$.

$$
\text{Var}(\texttt{mo}_t) = \text{Var}(\rho \texttt{mo}_{t-1} + \epsilon_t)  \\
\text{Var}(\texttt{mo}_t) = \text{Var}(\rho \texttt{mo}_{t-1}) + \text{Var}(\epsilon_t)
$$

The equality in the second line holds because of the independece
between of $\epsilon_t$ and $\epsilon_{t-1})$. 

Then, using the fact that $Var(cX) = c^2Var(X)$ for 
a constant $c$ and that, by stationarity,
$\textrm{Var}(\texttt{mo}_{t-1}) = \textrm{Var}(\texttt{mo}_{t})$,
we get:

$$
\text{Var}(\texttt{mo}_t)= \rho^2 \text{Var}( \texttt{mo}_{t})  + \sigma_\texttt{mo}^2 \\
\text{Var}(\texttt{mo}_t) = \frac{\sigma_\texttt{mo}^2}{1 - \rho^2}
$$

For the mean of $\texttt{mo}_t$:

$$
\mathbb{E}(\texttt{mo}_t) = \mathbb{E}(\rho \, \texttt{mo}_{t-1} + \epsilon_t) \\
\mathbb{E}(\texttt{mo}_t) = \mathbb{E}(\rho \, \texttt{mo}_{t-1}) + \mathbb{E}(\epsilon_t) \\
$$

Since $\mathbb{E}(\epsilon_t) = 0$ by assumption we have

$$
\mathbb{E}(\texttt{mo}_t) = \mathbb{E}(\rho \, \texttt{mo}_{t-1})  + 0\\
\mathbb{E}(\texttt{mo}_t) = \rho \, \mathbb{E}(\texttt{mo}_{t}) \\
\mathbb{E}(\texttt{mo}_t) - \rho \mathbb{E}(\texttt{mo}_t) = 0  \\
\mathbb{E}(\texttt{mo}_t) = 0/(1 - \rho)
$$

which for $\rho \neq 1$ yields $\mathbb{E}(\texttt{mo}_{t}) = 0$.

We thus get the marginal distribution for $\texttt{mo}_{t}$, which we 
will use for $\texttt{mo}_1$. The AR model for $mo_{1}$ can be 
specified as follows:

$$
\texttt{mo}_1 \sim \text{Normal}\left(0, \frac{\sigma_\texttt{mo}}{\sqrt{1 - \rho^2}}\right)
$$

Thus, the prior will have the following distribution:

$$
\texttt{mo}_t \sim \text{Normal}\left(\rho \, \texttt{mo}_{t-1}, \sigma_\texttt{mo}\right) \forall t > 1
$$

The Stan program of the last model is coded as follows:

```
// Hierarchical NB model with varying intercepts and slopes and
// month effect

functions {
  /*
  * Alternative to neg_binomial_2_log_rng() that
  * avoids potential numerical problems during warmup
  */
  int neg_binomial_2_log_safe_rng(real eta, real phi) {
    real gamma_rate = gamma_rng(phi, phi / exp(eta));
    if (gamma_rate >= exp(20.79))
      return -9;

    return poisson_rng(gamma_rate);
  }
}

data {
  int<lower = 1> N;
  int<lower = 0> complaints[N];
  vector<lower = 0>[N] traps;

  // 'exposure'
  vector[N] log_sq_foot;

  // building-level data
  int<lower = 1> K;
  int<lower = 1> J;
  int<lower = 1, upper = J> building_idx[N];
  matrix[J,K] building_data;

  // month info
  int<lower = 1> M;
  int<lower = 1, upper = M> mo_idx[N];
}
parameters {
  real<lower = 0> inv_phi;   // 1/phi (easier to think about prior for 1/phi instead of phi)

  // Varying intercept for the buildings
  vector[J] mu_raw;        // N(0,1) params for non-centered param of building-specific intercepts
  real<lower = 0> sigma_mu;  // sd of buildings-specific intercepts
  real alpha;              // 'global' intercept
  vector[K] zeta;          // coefficients on building-level predictors in model for mu

  // Varying slopes for the buildings
  vector[J] kappa_raw;       // N(0,1) params for non-centered param of building-specific slopes
  real<lower = 0> sigma_kappa; // sd of buildings-specific slopes
  real beta;                 // 'global' slope on traps variable
  vector[K] gamma;           // coefficients on building-level predictors in model for kappa

  // month-specific parameters
  real<lower = 0,upper = 1> rho_raw;  // used to construct rho, the AR(1) coefficient
  vector[M] mo_raw;
  real<lower = 0> sigma_mo;
}
transformed parameters {
  real phi = inv(inv_phi);

  // non-centered parameterization of building-specific intercepts and slopes
  vector[J] mu = alpha + building_data * zeta + sigma_mu * mu_raw;
  vector[J] kappa = beta + building_data * gamma + sigma_kappa * kappa_raw;

  // AR(1) process priors
  real rho = 2.0 * rho_raw - 1.0;
  vector[M] mo = sigma_mo * mo_raw;
  mo[1] /= sqrt(1 - rho^2);   //   mo[1] = mo[1]/sqrt(1-rho^2)

  // loop over the rest of the mo vector to add in the dependence on previous month
  for(m in 2:M) {

    mo[m] += rho * mo[m - 1];

  }
}
model {

  // Likelihood
  vector[N] eta = mu[building_idx] +
                  kappa[building_idx] .* traps +
                  mo[mo_idx] +
                  log_sq_foot;

  target += neg_binomial_2_log_lpmf(complaints | eta, phi);

  // Priors
  target += normal_lpdf(inv_phi | 0, 1) +
            // Priors on non-centered slopes
            normal_lpdf(kappa_raw | 0, 1) +
            normal_lpdf(sigma_kappa | 0, 1) +
            normal_lpdf(beta | -0.25, 1) +
            normal_lpdf(gamma | 0, 1) +
            // Priors on non-centered intercepts
            normal_lpdf(mu_raw | 0, 1) +
            normal_lpdf(sigma_mu | 0, 1) +
            normal_lpdf(alpha | log(4), 1) +
            normal_lpdf(zeta | 0, 1) +
            // Priors on non-centered months
            beta_lpdf(rho_raw | 10, 5) +
            normal_lpdf(mo_raw | 0, 1) +
            normal_lpdf(sigma_mo | 0, 1);

  // Alternative formulation
  // inv_phi ~ normal(0, 1);
  //
  // kappa_raw ~ normal(0,1) ;
  // sigma_kappa ~ normal(0, 1);
  // beta ~ normal(-0.25, 1);
  // gamma ~ normal(0, 1);
  //
  // mu_raw ~ normal(0,1) ;
  // sigma_mu ~ normal(0, 1);
  // alpha ~ normal(log(4), 1);
  // zeta ~ normal(0, 1);
  //
  // rho_raw ~ beta(10, 5);
  // mo_raw ~ normal(0, 1);
  // sigma_mo ~ normal(0, 1);
  //
  // complaints ~ neg_binomial_2_log(mu[building_idx] +
  //                                kappa[building_idx] .* traps +
  //                                mo[mo_idx] +
  //                                log_sq_foot,
  //                                phi);

}
generated quantities {
  int y_rep[N];
  for (n in 1:N) {
    real eta_n =
      mu[building_idx[n]] +
      kappa[building_idx[n]] * traps[n] +
      mo[mo_idx[n]] +
      log_sq_foot[n];

    y_rep[n] = neg_binomial_2_log_safe_rng(eta_n, phi);
  }
}


```


Let's compile the model

```{r}
comp_model_NB_hier_mos <- stan_model(
  'stan_programs/hier_multiple_neg_bin_ncp_var_slopes_mon.stan'
)
```

and run the algorithm to sample from the posterior.

```{r}
fitted_model_NB_hier_mos <- sampling(
    comp_model_NB_hier_mos,
    data = pest_data_longer,
    warmup = 1000L,
    iter = 2000L,
    chains = 4,
    control = list(
      adapt_delta = 0.95,
      max_treedepth = 15
    ),
    seed = mcmc_seed
)
```

Now we can print the parameters of the model.

```{r}
print(
  fitted_model_NB_hier_mos, 
  pars = c(
    'kappa',
    'beta',
    'alpha',
    'phi',
    'sigma_mu',
    'sigma_kappa',
    'mu',
    "zeta",
    "mo",
    "sigma_mo"
  )
)
```

In the interest of brevity, we won't go on expanding the model, though 
we certainly could. What other information would help us understand the
data generating process better? What other aspects of the data 
generating process might we want to capture that we're not capturing 
now?

As usual, we run through our posterior predictive checks.

```{r ppc-full-hier-mos}
y_rep <- as.matrix(
  fitted_model_NB_hier_mos, 
  pars = "y_rep"
)

ppc_dens_overlay(
  y = pest_data_longer$complaints,
  yrep = y_rep[1:200,]
)
```

```{r}
select_vec <- which(pest_data_longer$mo_idx %in% 1:12)

ppc_stat_grouped(
  y = pest_data_longer$complaints[select_vec],
  yrep = y_rep[,select_vec],
  group = pest_data_longer$mo_idx[select_vec],
  stat = 'mean'
)
```

As we can see, our monthly varying intercept has captured a monthly
pattern across all the buildings. We can also compare the prior and
posterior for the autoregressive parameter to see how much we've 
learned. Here are two different ways of comparing the prior and 
posterior visually:

```{r}
# 1) compare draws from prior and draws from posterior
rho_draws <- cbind(
  2 * rbeta(4000, 10, 5) - 1, # draw from prior
  as.matrix(
    fitted_model_NB_hier_mos, 
    pars = "rho"
  )
)

colnames(rho_draws) <- c("prior", "posterior")

mcmc_hist(
  rho_draws, 
  freq = FALSE, 
  binwidth = 0.025,
  facet_args = list(nrow = 2)
) + 
  xlim(-1, 1)


# 2) overlay prior density curve on posterior draws
gen_rho_prior <- function(x) {
  alpha <- 10; beta <- 5
  a <- -1; c <- 1
  lp <- (alpha - 1) * log(x - a) +
        (beta - 1) * log(c - x) -
        (alpha + beta - 1) * log(c - a) -
         lbeta(alpha, beta)
  return(exp(lp))
}

mcmc_hist(
  as.matrix(
    fitted_model_NB_hier_mos, 
    pars = "rho"
  ),
  freq = FALSE,
  binwidth = 0.01
) +
  overlay_function(fun = gen_rho_prior) +
  xlim(-1,1)
```

```{r}
print(
  fitted_model_NB_hier_mos, 
  pars = c('rho','sigma_mu','sigma_kappa','gamma')
)
```

```{r}
ppc_intervals(
  y = pest_data_longer$complaints,
  yrep = y_rep,
  x = pest_data_longer$traps
) +
  labs(
    x = "Number of traps", 
    y = "Number of complaints"
  )
```

It looks as if our model finally generates a reasonable posterior
predictive distribution for all numbers of traps, and appropriately
captures the tails of the data generating process.



<!--chapter:end:40-hierarchical_models_2.Rmd-->


# Model comparison {#day5}

Placeholder



<!--chapter:end:50-model_comparison.Rmd-->

`r if (knitr::is_html_output()) '
# References {-}
'`

<!--chapter:end:99-references.Rmd-->

